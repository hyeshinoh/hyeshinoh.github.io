<!DOCTYPE html>
<html lang=en>
<head><meta name="generator" content="Hexo 3.9.0">
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="google-site-verification" content="gKrpPp3pdUTTicqIbNv6e3j6c232Ae4ouHGND_G68cI">
    <meta name="description" content="jupyter notebook으로 보기 다룰 내용 Scrapy 개요 xpath xpath의 기본 문법 scrapy shell 환경에서 xpath scrapy jupyter notebook xpath 네이버 실시간 검색어, 다음실시간 검색어, 지마켓 베스트 200   scrapy 프로젝트를 만들어서 크롤링 네이버 영화 사이트에서 현재 상영영화 링크를 크롤링">
<meta name="keywords" content="programming,web,crawling,web_crawling,웹크롤링,selenium">
<meta property="og:type" content="article">
<meta property="og:title" content="Web crawling - Scrapy">
<meta property="og:url" content="https://hyeshinoh.github.io/2018/10/15/web_12_scrapy/index.html">
<meta property="og:site_name" content="우와팬더의 블로그">
<meta property="og:description" content="jupyter notebook으로 보기 다룰 내용 Scrapy 개요 xpath xpath의 기본 문법 scrapy shell 환경에서 xpath scrapy jupyter notebook xpath 네이버 실시간 검색어, 다음실시간 검색어, 지마켓 베스트 200   scrapy 프로젝트를 만들어서 크롤링 네이버 영화 사이트에서 현재 상영영화 링크를 크롤링">
<meta property="og:locale" content="en">
<meta property="og:updated_time" content="2019-08-15T15:25:03.625Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Web crawling - Scrapy">
<meta name="twitter:description" content="jupyter notebook으로 보기 다룰 내용 Scrapy 개요 xpath xpath의 기본 문법 scrapy shell 환경에서 xpath scrapy jupyter notebook xpath 네이버 실시간 검색어, 다음실시간 검색어, 지마켓 베스트 200   scrapy 프로젝트를 만들어서 크롤링 네이버 영화 사이트에서 현재 상영영화 링크를 크롤링">
    
    
        
          
              <link rel="shortcut icon" href="/images/favicon_panda.png">
          
        
        
          
            <link rel="icon" type="image/png" href="/images/favicon_panda.png" sizes="192x192">
          
        
        
          
            <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon_panda.png">
          
        
    
    <!-- title -->
    <title>Web crawling - Scrapy</title>
    <!-- styles -->
    <link rel="stylesheet" href="/css/style.css">
    <!-- persian styles -->
    
      <link rel="stylesheet" href="/css/rtl.css">
    
    <!-- rss -->
    
    
      <link rel="alternate" href="/atom.xml" title="우와팬더의 블로그" type="application/atom+xml"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
    
</head>

<body class="max-width mx-auto px3 ltr">    
      <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="header-post">
  <a id="menu-icon" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/categories/Diary">Diary</a></li>
         
          <li><a href="/categories/DataScience/">Data Science</a></li>
         
          <li><a href="/categories/Life/">Life</a></li>
         
          <li><a href="/categories/">Categories</a></li>
         
          <li><a href="/search/">Search</a></li>
        
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" href="/2018/10/15/2018-10-15-TIL/"><i class="fas fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" href="/2018/10/13/python_10_try & except/"><i class="fas fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" href="#"><i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" href="http://www.facebook.com/sharer.php?u=https://hyeshinoh.github.io/2018/10/15/web_12_scrapy/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://twitter.com/share?url=https://hyeshinoh.github.io/2018/10/15/web_12_scrapy/&text=Web crawling - Scrapy"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.linkedin.com/shareArticle?url=https://hyeshinoh.github.io/2018/10/15/web_12_scrapy/&title=Web crawling - Scrapy"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=https://hyeshinoh.github.io/2018/10/15/web_12_scrapy/&is_video=false&description=Web crawling - Scrapy"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Web crawling - Scrapy&body=Check out this article: https://hyeshinoh.github.io/2018/10/15/web_12_scrapy/"><i class="fas fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://getpocket.com/save?url=https://hyeshinoh.github.io/2018/10/15/web_12_scrapy/&title=Web crawling - Scrapy"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://reddit.com/submit?url=https://hyeshinoh.github.io/2018/10/15/web_12_scrapy/&title=Web crawling - Scrapy"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.stumbleupon.com/submit?url=https://hyeshinoh.github.io/2018/10/15/web_12_scrapy/&title=Web crawling - Scrapy"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://digg.com/submit?url=https://hyeshinoh.github.io/2018/10/15/web_12_scrapy/&title=Web crawling - Scrapy"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.tumblr.com/share/link?url=https://hyeshinoh.github.io/2018/10/15/web_12_scrapy/&name=Web crawling - Scrapy&description=&lt;p&gt;&lt;a href=&#34;https://github.com/hyeshinoh/Study_Web/blob/master/web_11_scrapy.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;jupyter notebook으로 보기&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;다룰-내용&#34;&gt;&lt;a href=&#34;#다룰-내용&#34; class=&#34;headerlink&#34; title=&#34;다룰 내용&#34;&gt;&lt;/a&gt;다룰 내용&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;Scrapy 개요&lt;/li&gt;
&lt;li&gt;xpath&lt;ul&gt;
&lt;li&gt;xpath의 기본 문법&lt;/li&gt;
&lt;li&gt;scrapy shell 환경에서 xpath&lt;/li&gt;
&lt;li&gt;scrapy jupyter notebook xpath&lt;/li&gt;
&lt;li&gt;네이버 실시간 검색어, 다음실시간 검색어, 지마켓 베스트 200&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;scrapy 프로젝트를 만들어서 크롤링&lt;ul&gt;
&lt;li&gt;네이버 영화 사이트에서 현재 상영영화 링크를 크롤링&lt;/li&gt;
&lt;li&gt;크롤링한 링크에서 영화 제목과 누적관객수 데이터를 크롤링&lt;/li&gt;
&lt;li&gt;csv 파일로 저장&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;"><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
</ul>

    </div>
    <div id="toc">
      <ol class="toc"><li class="toc-item toc-level-4"><a class="toc-link" href="#다룰-내용"><span class="toc-number">1.</span> <span class="toc-text">다룰 내용</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-Scrapy"><span class="toc-number"></span> <span class="toc-text">1. Scrapy</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-xpath"><span class="toc-number"></span> <span class="toc-text">2. xpath</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-xpath의-기본-문법"><span class="toc-number"></span> <span class="toc-text">2.1 xpath의 기본 문법</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-네이버-실시간-검색어-크롤링"><span class="toc-number"></span> <span class="toc-text">2.2 네이버 실시간 검색어 크롤링</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-스크래피-셸-사용"><span class="toc-number">1.</span> <span class="toc-text">(1) 스크래피 셸 사용</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-jupyter-notebook-사용"><span class="toc-number">2.</span> <span class="toc-text">(2) jupyter notebook 사용</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#웹페이지에-연결"><span class="toc-number">2.1.</span> <span class="toc-text">웹페이지에 연결</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#네이버-실시간-검색어-1위-element-객체"><span class="toc-number">2.2.</span> <span class="toc-text">네이버 실시간 검색어 1위 element 객체</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#네이버-실시간-검색어-20개-element-객체"><span class="toc-number">2.3.</span> <span class="toc-text">네이버 실시간 검색어 20개 element 객체</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#객체의-text만-추출하기"><span class="toc-number">2.4.</span> <span class="toc-text">객체의 text만 추출하기</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#문자열만-추출하기"><span class="toc-number">2.5.</span> <span class="toc-text">문자열만 추출하기</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#을-이용해서-가져오기"><span class="toc-number">2.6.</span> <span class="toc-text">.을 이용해서 가져오기</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-다음-실시간-검색어-크롤링"><span class="toc-number"></span> <span class="toc-text">2.3 다음 실시간 검색어 크롤링</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#다음-실시간-검색어-리스트-출력"><span class="toc-number">0.1.</span> <span class="toc-text">다음 실시간 검색어 리스트 출력</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-gmarket-best-item-200-크롤링"><span class="toc-number"></span> <span class="toc-text">2.4 gmarket best item 200 크롤링</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#웹페이지에-연결-1"><span class="toc-number">0.1.</span> <span class="toc-text">웹페이지에 연결</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#베스트-200-아이템-제목-문자열-리스트로-가져오기"><span class="toc-number">0.2.</span> <span class="toc-text">베스트 200 아이템 제목 문자열 리스트로 가져오기</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#200개-아이템에서-li-클래스가-first인-데이터만-가져오기"><span class="toc-number">0.3.</span> <span class="toc-text">200개 아이템에서 li 클래스가 first인 데이터만 가져오기</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#200개-아이템에서-li-클래스가-first가-아닌-데이터만-가져오기"><span class="toc-number">0.4.</span> <span class="toc-text">200개 아이템에서 li 클래스가 first가 아닌 데이터만 가져오기</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Scrapy-project"><span class="toc-number"></span> <span class="toc-text">3. Scrapy project</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-scrapy-프로젝트-생성"><span class="toc-number"></span> <span class="toc-text">3.1 scrapy 프로젝트 생성</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-scrapy-프로젝트-파일-설명"><span class="toc-number"></span> <span class="toc-text">3.2 scrapy 프로젝트 파일 설명</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#project-구조"><span class="toc-number">1.</span> <span class="toc-text">project 구조</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-크롤링-코드-작성"><span class="toc-number"></span> <span class="toc-text">3.3 크롤링 코드 작성</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#※-yield"><span class="toc-number">1.</span> <span class="toc-text">※ yield</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#iterator와-generator"><span class="toc-number">1.1.</span> <span class="toc-text">iterator와 generator</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-items-py"><span class="toc-number">2.</span> <span class="toc-text">(1) items.py</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-spider-py"><span class="toc-number">3.</span> <span class="toc-text">(2) spider.py</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#크롤링-함수-작성"><span class="toc-number">4.</span> <span class="toc-text">크롤링 함수 작성</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#nm-spider-py-작성"><span class="toc-number">5.</span> <span class="toc-text">nm_spider.py 작성</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-settings-py"><span class="toc-number">6.</span> <span class="toc-text">(3) settings.py</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-spider-실행"><span class="toc-number">7.</span> <span class="toc-text">(4) spider 실행</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-pipeline-py"><span class="toc-number">8.</span> <span class="toc-text">(5) pipeline.py</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#덧"><span class="toc-number"></span> <span class="toc-text">덧</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#참고자료"><span class="toc-number">1.</span> <span class="toc-text">참고자료</span></a></li></ol>
    </div>
  </span>
</div>

    
    <div class="content index py4">
        
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle" itemprop="name headline">
        Web crawling - Scrapy
    </h1>



    <div class="meta">
      <span class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span itemprop="name">우와팬더의 블로그</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2018-10-15T12:27:51.000Z" itemprop="datePublished">2018-10-15</time>
        
      
    </div>


      
    <div class="article-category">
        <i class="fas fa-archive"></i>
        <a class="category-link" href="/categories/DataScience/">DataScience</a> › <a class="category-link" href="/categories/DataScience/Web-웹/">Web 웹</a>
    </div>


      
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link" href="/tags/crawling/">crawling</a>, <a class="tag-link" href="/tags/programming/">programming</a>, <a class="tag-link" href="/tags/selenium/">selenium</a>, <a class="tag-link" href="/tags/web/">web</a>, <a class="tag-link" href="/tags/web-crawling/">web_crawling</a>, <a class="tag-link" href="/tags/웹크롤링/">웹크롤링</a>
    </div>


    </div>
  </header>
  

  <div class="content" itemprop="articleBody">
    <p><a href="https://github.com/hyeshinoh/Study_Web/blob/master/web_11_scrapy.ipynb" target="_blank" rel="noopener">jupyter notebook으로 보기</a></p>
<h4 id="다룰-내용"><a href="#다룰-내용" class="headerlink" title="다룰 내용"></a>다룰 내용</h4><ul>
<li>Scrapy 개요</li>
<li>xpath<ul>
<li>xpath의 기본 문법</li>
<li>scrapy shell 환경에서 xpath</li>
<li>scrapy jupyter notebook xpath</li>
<li>네이버 실시간 검색어, 다음실시간 검색어, 지마켓 베스트 200</li>
</ul>
</li>
<li>scrapy 프로젝트를 만들어서 크롤링<ul>
<li>네이버 영화 사이트에서 현재 상영영화 링크를 크롤링</li>
<li>크롤링한 링크에서 영화 제목과 누적관객수 데이터를 크롤링</li>
<li>csv 파일로 저장</li>
</ul>
</li>
</ul>
<a id="more"></a> 
<h2 id="1-Scrapy"><a href="#1-Scrapy" class="headerlink" title="1. Scrapy"></a>1. Scrapy</h2><ul>
<li>웹사이트에서 데이터 추출을 하기 위한 오픈소스 프레임워크 (패키지가 아님)</li>
<li><a href="http://scrapy.org" target="_blank" rel="noopener">http://scrapy.org</a></li>
<li>설치<ul>
<li>windows: <code>conda install -c conda-forge scrapy</code></li>
<li>mac: <code>pip3 install scrapy</code></li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br></pre></td></tr></table></figure>
<h2 id="2-xpath"><a href="#2-xpath" class="headerlink" title="2. xpath"></a>2. xpath</h2><p>지금까지 배웠던 css selector가 아닌 xpath를 이용해서도 웹페이지의 html element를 선택할 수 있다.</p>
<h3 id="2-1-xpath의-기본-문법"><a href="#2-1-xpath의-기본-문법" class="headerlink" title="2.1 xpath의 기본 문법"></a>2.1 xpath의 기본 문법</h3><p>예시 xpath: 네이버 실시간 검색어 순위에서 [copy xpath]로 복사<br><code>//*[@id=&quot;PM_ID_ct&quot;]/div[1]/div[2]/div[2]/div[1]/div/ul/li[1]/a/span[2]</code></p>
<ul>
<li><code>//</code>: 최상위 element를 의미</li>
<li><code>*</code>: 조건에 맞는 하위 element를 모두 살펴봄 (css selector에서 하위 element 검색: 한칸 띄우기)</li>
<li><code>[@id=&quot;PM_ID_ct&quot;]</code>: id가 PM_ID_ct 인 element를 선택<ul>
<li><code>[@&lt;key&gt;=&lt;value&gt;]</code> 형태 (css selector와 다르게 모든 속성을 <code>@&lt;key&gt;</code>로 표현)</li>
</ul>
</li>
<li><code>/</code>: 바로 아래 element를 살펴봄 (css selector의 <code>&gt;</code> 기호와 같은 의미)</li>
<li><code>[number]</code>: number번째 element를 선택 (0번부터가 아니라 1번부터 시작함)</li>
<li><code>.</code>: 현재 element를 의미</li>
<li><code>not()</code>: 조건이 아닌 element를 찾음<ul>
<li><code>not([@id=test})</code></li>
</ul>
</li>
</ul>
<h3 id="2-2-네이버-실시간-검색어-크롤링"><a href="#2-2-네이버-실시간-검색어-크롤링" class="headerlink" title="2.2 네이버 실시간 검색어 크롤링"></a>2.2 네이버 실시간 검색어 크롤링</h3><h4 id="1-스크래피-셸-사용"><a href="#1-스크래피-셸-사용" class="headerlink" title="(1) 스크래피 셸 사용"></a>(1) 스크래피 셸 사용</h4><ul>
<li><code>$ scrapy shell &quot;&lt;url&gt;&quot;</code></li>
</ul>
<h4 id="2-jupyter-notebook-사용"><a href="#2-jupyter-notebook-사용" class="headerlink" title="(2) jupyter notebook 사용"></a>(2) jupyter notebook 사용</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> scrapy.http <span class="keyword">import</span> TextResponse</span><br></pre></td></tr></table></figure>
<h5 id="웹페이지에-연결"><a href="#웹페이지에-연결" class="headerlink" title="웹페이지에 연결"></a>웹페이지에 연결</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">url = <span class="string">"http://naver.com"</span></span><br><span class="line">rep = requests.get(url)</span><br><span class="line">response = TextResponse(rep.url, body=rep.text, encoding=<span class="string">"utf-8"</span>)</span><br></pre></td></tr></table></figure>
<h5 id="네이버-실시간-검색어-1위-element-객체"><a href="#네이버-실시간-검색어-1위-element-객체" class="headerlink" title="네이버 실시간 검색어 1위 element 객체"></a>네이버 실시간 검색어 1위 element 객체</h5><ul>
<li>xpath로 select하면 list로 return</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">response.xpath(<span class="string">'//*[@id="PM_ID_ct"]/div[1]/div[2]/div[2]/div[1]/div/ul/li[1]/a/span[2]'</span>)</span><br></pre></td></tr></table></figure>
<pre><code>[&lt;Selector xpath=&apos;//*[@id=&quot;PM_ID_ct&quot;]/div[1]/div[2]/div[2]/div[1]/div/ul/li[1]/a/span[2]&apos; data=&apos;&lt;span class=&quot;ah_k&quot;&gt;우왁굳&lt;/span&gt;&apos;&gt;]
</code></pre><h5 id="네이버-실시간-검색어-20개-element-객체"><a href="#네이버-실시간-검색어-20개-element-객체" class="headerlink" title="네이버 실시간 검색어 20개 element 객체"></a>네이버 실시간 검색어 20개 element 객체</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 네이버 실시간 검색어 20개 element 객체</span></span><br><span class="line">response.xpath(<span class="string">'//*[@id="PM_ID_ct"]/div[1]/div[2]/div[2]/div[1]/div/ul/li/a/span[2]'</span>)</span><br></pre></td></tr></table></figure>
<pre><code>[&lt;Selector xpath=&apos;//*[@id=&quot;PM_ID_ct&quot;]/div[1]/div[2]/div[2]/div[1]/div/ul/li/a/span[2]&apos; data=&apos;&lt;span class=&quot;ah_k&quot;&gt;우왁굳&lt;/span&gt;&apos;&gt;,
 &lt;Selector xpath=&apos;//*[@id=&quot;PM_ID_ct&quot;]/div[1]/div[2]/div[2]/div[1]/div/ul/li/a/span[2]&apos; data=&apos;&lt;span class=&quot;ah_k&quot;&gt;홍현희&lt;/span&gt;&apos;&gt;,
 &lt;Selector xpath=&apos;//*[@id=&quot;PM_ID_ct&quot;]/div[1]/div[2]/div[2]/div[1]/div/ul/li/a/span[2]&apos; data=&apos;&lt;span class=&quot;ah_k&quot;&gt;김수현&lt;/span&gt;&apos;&gt;,
 &lt;Selector xpath=&apos;//*[@id=&quot;PM_ID_ct&quot;]/div[1]/div[2]/div[2]/div[1]/div/ul/li/a/span[2]&apos; data=&apos;&lt;span class=&quot;ah_k&quot;&gt;오영택&lt;/span&gt;&apos;&gt;,
 &lt;Selector xpath=&apos;//*[@id=&quot;PM_ID_ct&quot;]/div[1]/div[2]/div[2]/div[1]/div/ul/li/a/span[2]&apos; data=&apos;&lt;span class=&quot;ah_k&quot;&gt;미세먼지&lt;/span&gt;&apos;&gt;,
 &lt;Selector xpath=&apos;//*[@id=&quot;PM_ID_ct&quot;]/div[1]/div[2]/div[2]/div[1]/div/ul/li/a/span[2]&apos; data=&apos;&lt;span class=&quot;ah_k&quot;&gt;주윤발&lt;/span&gt;&apos;&gt;,
 &lt;Selector xpath=&apos;//*[@id=&quot;PM_ID_ct&quot;]/div[1]/div[2]/div[2]/div[1]/div/ul/li/a/span[2]&apos; data=&apos;&lt;span class=&quot;ah_k&quot;&gt;박지원&lt;/span&gt;&apos;&gt;,
 &lt;Selector xpath=&apos;//*[@id=&quot;PM_ID_ct&quot;]/div[1]/div[2]/div[2]/div[1]/div/ul/li/a/span[2]&apos; data=&apos;&lt;span class=&quot;ah_k&quot;&gt;환희유치원&lt;/span&gt;&apos;&gt;,
 &lt;Selector xpath=&apos;//*[@id=&quot;PM_ID_ct&quot;]/div[1]/div[2]/div[2]/div[1]/div/ul/li/a/span[2]&apos; data=&apos;&lt;span class=&quot;ah_k&quot;&gt;제이쓴&lt;/span&gt;&apos;&gt;,
 &lt;Selector xpath=&apos;//*[@id=&quot;PM_ID_ct&quot;]/div[1]/div[2]/div[2]/div[1]/div/ul/li/a/span[2]&apos; data=&apos;&lt;span class=&quot;ah_k&quot;&gt;동탄 환희유치원&lt;/span&gt;&apos;&gt;,
 &lt;Selector xpath=&apos;//*[@id=&quot;PM_ID_ct&quot;]/div[1]/div[2]/div[2]/div[1]/div/ul/li/a/span[2]&apos; data=&apos;&lt;span class=&quot;ah_k&quot;&gt;브리짓 존스의 베이비&lt;/span&gt;&apos;&gt;,
 &lt;Selector xpath=&apos;//*[@id=&quot;PM_ID_ct&quot;]/div[1]/div[2]/div[2]/div[1]/div/ul/li/a/span[2]&apos; data=&apos;&lt;span class=&quot;ah_k&quot;&gt;고현정&lt;/span&gt;&apos;&gt;,
 &lt;Selector xpath=&apos;//*[@id=&quot;PM_ID_ct&quot;]/div[1]/div[2]/div[2]/div[1]/div/ul/li/a/span[2]&apos; data=&apos;&lt;span class=&quot;ah_k&quot;&gt;추상미&lt;/span&gt;&apos;&gt;,
 &lt;Selector xpath=&apos;//*[@id=&quot;PM_ID_ct&quot;]/div[1]/div[2]/div[2]/div[1]/div/ul/li/a/span[2]&apos; data=&apos;&lt;span class=&quot;ah_k&quot;&gt;조현민&lt;/span&gt;&apos;&gt;,
 &lt;Selector xpath=&apos;//*[@id=&quot;PM_ID_ct&quot;]/div[1]/div[2]/div[2]/div[1]/div/ul/li/a/span[2]&apos; data=&apos;&lt;span class=&quot;ah_k&quot;&gt;장학영&lt;/span&gt;&apos;&gt;,
 &lt;Selector xpath=&apos;//*[@id=&quot;PM_ID_ct&quot;]/div[1]/div[2]/div[2]/div[1]/div/ul/li/a/span[2]&apos; data=&apos;&lt;span class=&quot;ah_k&quot;&gt;강병규&lt;/span&gt;&apos;&gt;,
 &lt;Selector xpath=&apos;//*[@id=&quot;PM_ID_ct&quot;]/div[1]/div[2]/div[2]/div[1]/div/ul/li/a/span[2]&apos; data=&apos;&lt;span class=&quot;ah_k&quot;&gt;이한샘&lt;/span&gt;&apos;&gt;,
 &lt;Selector xpath=&apos;//*[@id=&quot;PM_ID_ct&quot;]/div[1]/div[2]/div[2]/div[1]/div/ul/li/a/span[2]&apos; data=&apos;&lt;span class=&quot;ah_k&quot;&gt;자이언티&lt;/span&gt;&apos;&gt;,
 &lt;Selector xpath=&apos;//*[@id=&quot;PM_ID_ct&quot;]/div[1]/div[2]/div[2]/div[1]/div/ul/li/a/span[2]&apos; data=&apos;&lt;span class=&quot;ah_k&quot;&gt;오늘 미세먼지 농도&lt;/span&gt;&apos;&gt;,
 &lt;Selector xpath=&apos;//*[@id=&quot;PM_ID_ct&quot;]/div[1]/div[2]/div[2]/div[1]/div/ul/li/a/span[2]&apos; data=&apos;&lt;span class=&quot;ah_k&quot;&gt;존조&lt;/span&gt;&apos;&gt;]
</code></pre><h5 id="객체의-text만-추출하기"><a href="#객체의-text만-추출하기" class="headerlink" title="객체의 text만 추출하기"></a>객체의 text만 추출하기</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">response.xpath(<span class="string">'//*[@id="PM_ID_ct"]/div[1]/div[2]/div[2]/div[1]/div/ul/li/a/span[2]/text()'</span>)</span><br></pre></td></tr></table></figure>
<pre><code>[&lt;Selector xpath=&apos;//*[@id=&quot;PM_ID_ct&quot;]/div[1]/div[2]/div[2]/div[1]/div/ul/li/a/span[2]/text()&apos; data=&apos;우왁굳&apos;&gt;,
 &lt;Selector xpath=&apos;//*[@id=&quot;PM_ID_ct&quot;]/div[1]/div[2]/div[2]/div[1]/div/ul/li/a/span[2]/text()&apos; data=&apos;홍현희&apos;&gt;,
 &lt;Selector xpath=&apos;//*[@id=&quot;PM_ID_ct&quot;]/div[1]/div[2]/div[2]/div[1]/div/ul/li/a/span[2]/text()&apos; data=&apos;김수현&apos;&gt;,
 &lt;Selector xpath=&apos;//*[@id=&quot;PM_ID_ct&quot;]/div[1]/div[2]/div[2]/div[1]/div/ul/li/a/span[2]/text()&apos; data=&apos;오영택&apos;&gt;,
 &lt;Selector xpath=&apos;//*[@id=&quot;PM_ID_ct&quot;]/div[1]/div[2]/div[2]/div[1]/div/ul/li/a/span[2]/text()&apos; data=&apos;미세먼지&apos;&gt;,
 &lt;Selector xpath=&apos;//*[@id=&quot;PM_ID_ct&quot;]/div[1]/div[2]/div[2]/div[1]/div/ul/li/a/span[2]/text()&apos; data=&apos;주윤발&apos;&gt;,
 &lt;Selector xpath=&apos;//*[@id=&quot;PM_ID_ct&quot;]/div[1]/div[2]/div[2]/div[1]/div/ul/li/a/span[2]/text()&apos; data=&apos;박지원&apos;&gt;,
 &lt;Selector xpath=&apos;//*[@id=&quot;PM_ID_ct&quot;]/div[1]/div[2]/div[2]/div[1]/div/ul/li/a/span[2]/text()&apos; data=&apos;환희유치원&apos;&gt;,
 &lt;Selector xpath=&apos;//*[@id=&quot;PM_ID_ct&quot;]/div[1]/div[2]/div[2]/div[1]/div/ul/li/a/span[2]/text()&apos; data=&apos;제이쓴&apos;&gt;,
 &lt;Selector xpath=&apos;//*[@id=&quot;PM_ID_ct&quot;]/div[1]/div[2]/div[2]/div[1]/div/ul/li/a/span[2]/text()&apos; data=&apos;동탄 환희유치원&apos;&gt;,
 &lt;Selector xpath=&apos;//*[@id=&quot;PM_ID_ct&quot;]/div[1]/div[2]/div[2]/div[1]/div/ul/li/a/span[2]/text()&apos; data=&apos;브리짓 존스의 베이비&apos;&gt;,
 &lt;Selector xpath=&apos;//*[@id=&quot;PM_ID_ct&quot;]/div[1]/div[2]/div[2]/div[1]/div/ul/li/a/span[2]/text()&apos; data=&apos;고현정&apos;&gt;,
 &lt;Selector xpath=&apos;//*[@id=&quot;PM_ID_ct&quot;]/div[1]/div[2]/div[2]/div[1]/div/ul/li/a/span[2]/text()&apos; data=&apos;추상미&apos;&gt;,
 &lt;Selector xpath=&apos;//*[@id=&quot;PM_ID_ct&quot;]/div[1]/div[2]/div[2]/div[1]/div/ul/li/a/span[2]/text()&apos; data=&apos;조현민&apos;&gt;,
 &lt;Selector xpath=&apos;//*[@id=&quot;PM_ID_ct&quot;]/div[1]/div[2]/div[2]/div[1]/div/ul/li/a/span[2]/text()&apos; data=&apos;장학영&apos;&gt;,
 &lt;Selector xpath=&apos;//*[@id=&quot;PM_ID_ct&quot;]/div[1]/div[2]/div[2]/div[1]/div/ul/li/a/span[2]/text()&apos; data=&apos;강병규&apos;&gt;,
 &lt;Selector xpath=&apos;//*[@id=&quot;PM_ID_ct&quot;]/div[1]/div[2]/div[2]/div[1]/div/ul/li/a/span[2]/text()&apos; data=&apos;이한샘&apos;&gt;,
 &lt;Selector xpath=&apos;//*[@id=&quot;PM_ID_ct&quot;]/div[1]/div[2]/div[2]/div[1]/div/ul/li/a/span[2]/text()&apos; data=&apos;자이언티&apos;&gt;,
 &lt;Selector xpath=&apos;//*[@id=&quot;PM_ID_ct&quot;]/div[1]/div[2]/div[2]/div[1]/div/ul/li/a/span[2]/text()&apos; data=&apos;오늘 미세먼지 농도&apos;&gt;,
 &lt;Selector xpath=&apos;//*[@id=&quot;PM_ID_ct&quot;]/div[1]/div[2]/div[2]/div[1]/div/ul/li/a/span[2]/text()&apos; data=&apos;존조&apos;&gt;]
</code></pre><h5 id="문자열만-추출하기"><a href="#문자열만-추출하기" class="headerlink" title="문자열만 추출하기"></a>문자열만 추출하기</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">response.xpath(<span class="string">'//*[@id="PM_ID_ct"]/div[1]/div[2]/div[2]/div[1]/div/ul/li/a/span[2]/text()'</span>)[:<span class="number">10</span>].extract()</span><br></pre></td></tr></table></figure>
<pre><code>[&apos;우왁굳&apos;, &apos;홍현희&apos;, &apos;김수현&apos;, &apos;오영택&apos;, &apos;미세먼지&apos;, &apos;주윤발&apos;, &apos;박지원&apos;, &apos;환희유치원&apos;, &apos;제이쓴&apos;, &apos;동탄 환희유치원&apos;]
</code></pre><h5 id="을-이용해서-가져오기"><a href="#을-이용해서-가져오기" class="headerlink" title=".을 이용해서 가져오기"></a><code>.</code>을 이용해서 가져오기</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">keywords = response.xpath(<span class="string">'//*[@id="PM_ID_ct"]/div[1]/div[2]/div[2]/div[1]/div/ul/li'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> keyword <span class="keyword">in</span> keywords:</span><br><span class="line">    print(keyword.xpath(<span class="string">'./a/span[2]/text()'</span>)[<span class="number">0</span>].extract())</span><br></pre></td></tr></table></figure>
<pre><code>우왁굳
홍현희
김수현
오영택
미세먼지
주윤발
박지원
환희유치원
제이쓴
동탄 환희유치원
브리짓 존스의 베이비
고현정
추상미
조현민
장학영
강병규
이한샘
자이언티
오늘 미세먼지 농도
존조
</code></pre><h3 id="2-3-다음-실시간-검색어-크롤링"><a href="#2-3-다음-실시간-검색어-크롤링" class="headerlink" title="2.3 다음 실시간 검색어 크롤링"></a>2.3 다음 실시간 검색어 크롤링</h3><h5 id="다음-실시간-검색어-리스트-출력"><a href="#다음-실시간-검색어-리스트-출력" class="headerlink" title="다음 실시간 검색어 리스트 출력"></a>다음 실시간 검색어 리스트 출력</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">url = <span class="string">"http://daum.net"</span></span><br><span class="line">rep = requests.get(url)</span><br><span class="line">response = TextResponse(rep.url, body=rep.text, encoding=<span class="string">"utf-8"</span>)</span><br><span class="line">response.xpath(<span class="string">'//*[@id="mArticle"]/div[2]/div[1]/div[2]/div[1]/ol/li/div/div[1]/span[2]/a/text()'</span>).extract()</span><br></pre></td></tr></table></figure>
<pre><code>[&apos;박지원&apos;, &apos;추상미&apos;, &apos;우왁굳&apos;, &apos;강예빈&apos;, &apos;김수현 아나운서&apos;, &apos;장학영&apos;, &apos;환희유치원&apos;, &apos;미세먼지&apos;, &apos;존조&apos;, &apos;서유정&apos;]
</code></pre><h3 id="2-4-gmarket-best-item-200-크롤링"><a href="#2-4-gmarket-best-item-200-크롤링" class="headerlink" title="2.4 gmarket best item 200 크롤링"></a>2.4 gmarket best item 200 크롤링</h3><h5 id="웹페이지에-연결-1"><a href="#웹페이지에-연결-1" class="headerlink" title="웹페이지에 연결"></a>웹페이지에 연결</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">url = <span class="string">"http://corners.gmarket.co.kr/Bestsellers"</span></span><br><span class="line">rep = requests.get(url)</span><br><span class="line">response = TextResponse(rep.url, body=rep.text, encoding=<span class="string">"utf-8"</span>)</span><br></pre></td></tr></table></figure>
<h5 id="베스트-200-아이템-제목-문자열-리스트로-가져오기"><a href="#베스트-200-아이템-제목-문자열-리스트로-가져오기" class="headerlink" title="베스트 200 아이템 제목 문자열 리스트로 가져오기"></a>베스트 200 아이템 제목 문자열 리스트로 가져오기</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">titles = response.xpath(<span class="string">'//*[@id="gBestWrap"]/div/div[3]/div[2]/ul/li/a/text()'</span>).extract()</span><br><span class="line">print(len(titles))</span><br><span class="line">titles[<span class="number">195</span>:<span class="number">199</span>]</span><br></pre></td></tr></table></figure>
<pre><code>200

[&apos;일본수출 초극세사이불/백화점납품/ 피톤치드가공10mm&apos;,
 &apos;제로스킨 아이폰 갤럭시 핸드폰케이스 6 7 8 X S 노트&apos;,
 &apos;(국산)고급 반코팅 100켤레 이중코팅 면 목장갑 작업&apos;,
 &apos;[다이소]공식판매처/택배박스/봉투/로고인쇄/당일발송/소량&apos;]
</code></pre><h5 id="200개-아이템에서-li-클래스가-first인-데이터만-가져오기"><a href="#200개-아이템에서-li-클래스가-first인-데이터만-가져오기" class="headerlink" title="200개 아이템에서 li 클래스가 first인 데이터만 가져오기"></a>200개 아이템에서 li 클래스가 first인 데이터만 가져오기</h5><ul>
<li>클래스가 first인 아이템은 한 줄에 4개씩 나타나는 상품 중 각 줄의 첫번째 상품</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">titles = response.xpath(<span class="string">'//*[@id="gBestWrap"]/div/div[3]/div[2]/ul/li[@class="first"]/a/text()'</span>).extract()</span><br><span class="line">len(titles)</span><br></pre></td></tr></table></figure>
<pre><code>50
</code></pre><h5 id="200개-아이템에서-li-클래스가-first가-아닌-데이터만-가져오기"><a href="#200개-아이템에서-li-클래스가-first가-아닌-데이터만-가져오기" class="headerlink" title="200개 아이템에서 li 클래스가 first가 아닌 데이터만 가져오기"></a>200개 아이템에서 li 클래스가 first가 아닌 데이터만 가져오기</h5><ul>
<li><code>not()</code>을 사용</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">titles = response.xpath(<span class="string">'//*[@id="gBestWrap"]/div/div[3]/div[2]/ul/li[not(@class="first")]/a/text()'</span>).extract()</span><br><span class="line">len(titles)</span><br></pre></td></tr></table></figure>
<pre><code>150
</code></pre><h2 id="3-Scrapy-project"><a href="#3-Scrapy-project" class="headerlink" title="3. Scrapy project"></a>3. Scrapy project</h2><ul>
<li>jupyter notebook이 아닌 atom에서 작성</li>
<li>네이버 영화 페이지에서 현재 상영되고 있는 영화의 제목과 관람객수를 크롤링</li>
</ul>
<h3 id="3-1-scrapy-프로젝트-생성"><a href="#3-1-scrapy-프로젝트-생성" class="headerlink" title="3.1 scrapy 프로젝트 생성"></a>3.1 scrapy 프로젝트 생성</h3><ul>
<li>project 생성: <code>$ scrapy startproject &lt;project_name&gt;</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">! scrapy startproject crawler</span><br></pre></td></tr></table></figure>
<pre><code>New Scrapy project &apos;crawler&apos;, using template directory &apos;/usr/local/lib/python3.6/site-packages/scrapy/templates/project&apos;, created in:
    /Users/hyeshinoh/Workspace/Study_Web/crawler

You can start your first spider with:
    cd crawler
    scrapy genspider example example.com
</code></pre><h3 id="3-2-scrapy-프로젝트-파일-설명"><a href="#3-2-scrapy-프로젝트-파일-설명" class="headerlink" title="3.2 scrapy 프로젝트 파일 설명"></a>3.2 scrapy 프로젝트 파일 설명</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">! tree crawler</span><br></pre></td></tr></table></figure>
<pre><code>crawler
├── crawler
│   ├── __init__.py
│   ├── __pycache__
│   ├── items.py
│   ├── middlewares.py
│   ├── pipelines.py
│   ├── settings.py
│   └── spiders
│       ├── __init__.py
│       └── __pycache__
└── scrapy.cfg

4 directories, 7 files
</code></pre><h4 id="project-구조"><a href="#project-구조" class="headerlink" title="project 구조"></a>project 구조</h4><ul>
<li>spiders directory <ul>
<li>어떤 웹사이트를 어떻게 크롤링할 것인가를 명시하고, 각각의 웹 페이지의 어떤 부분을 스크래핑할 것인지 명시하는 클래스가 모여있는 디렉토리</li>
<li>여러개의 spider.py 파일을 만들어 사용할 수 있음</li>
</ul>
</li>
<li>items.py<ul>
<li>크롤링하는 데이터에 대해 정의하는 클래스가 있는 파일(MVC → M)</li>
</ul>
</li>
<li>pipelines.py<ul>
<li>item 객체 형태로 크롤링을 하고 출력하기 전에 item을 받아서 실행하는 파일이 정의되어 있는 파일</li>
<li>item을 자유롭게 가공하거나 다양한 파일 형태로 저장할 수 있도록 하는 클래스</li>
</ul>
</li>
<li>settings.py<ul>
<li>spider나 item pipeline 등이 어떻게 동작하게 할지에 대한 세부적 설정이 담겨 있는 파일 </li>
<li>e.g. robots.txt 정책을 따를 것인지 안 따를 것인지, pipeline을 사용할지 안 할지</li>
</ul>
</li>
</ul>
<h3 id="3-3-크롤링-코드-작성"><a href="#3-3-크롤링-코드-작성" class="headerlink" title="3.3 크롤링 코드 작성"></a>3.3 크롤링 코드 작성</h3><h4 id="※-yield"><a href="#※-yield" class="headerlink" title="※ yield"></a>※ yield</h4><h5 id="iterator와-generator"><a href="#iterator와-generator" class="headerlink" title="iterator와 generator"></a>iterator와 generator</h5><ul>
<li>iterator: 순서가 있는 데이터의 집합</li>
<li>generator: 함수가 호출될 때마다 순서대로 결과가 나오는 집합<ul>
<li><code>return</code>으로 한번에 데이터를 return하는 것보다 <code>yield</code>로 하나씩 return하면 resource를 절약할 수 있음</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># iterator data</span></span><br><span class="line">ls = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># generator data</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">number</span><span class="params">()</span>:</span>    <span class="comment"># generator를 만드는 함수</span></span><br><span class="line">    <span class="keyword">yield</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">yield</span> <span class="number">2</span></span><br><span class="line">    <span class="keyword">yield</span> <span class="number">3</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">n = number()</span><br><span class="line">n</span><br></pre></td></tr></table></figure>
<pre><code>&lt;generator object number at 0x11052c620&gt;
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">n.__next__()</span><br></pre></td></tr></table></figure>
<pre><code>1
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">n.__next__()</span><br></pre></td></tr></table></figure>
<pre><code>2
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">n.__next__()</span><br></pre></td></tr></table></figure>
<pre><code>3
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">n.__next__()</span><br></pre></td></tr></table></figure>
<pre><code>---------------------------------------------------------------------------

StopIteration                             Traceback (most recent call last)

&lt;ipython-input-23-8d5cb7b534a9&gt; in &lt;module&gt;()
----&gt; 1 n.__next__()


StopIteration: 
</code></pre><h4 id="1-items-py"><a href="#1-items-py" class="headerlink" title="(1) items.py"></a>(1) items.py</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#######################################################################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define here the models for your scraped items</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># See documentation in:</span></span><br><span class="line"><span class="comment"># https://doc.scrapy.org/en/latest/topics/items.html</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CrawlerItem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line">    <span class="comment"># define the fields for your item here like:</span></span><br><span class="line">    title = scrapy.Field()</span><br><span class="line">    count = scrapy.Field()</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#######################################################################################</span></span><br></pre></td></tr></table></figure>
<h4 id="2-spider-py"><a href="#2-spider-py" class="headerlink" title="(2) spider.py"></a>(2) spider.py</h4><ul>
<li>가장 먼저 실행되는 파일</li>
<li>기본적 변수<ul>
<li>name: scrapy 명령어로 spider를 실행할 때 argument로 쓰는 name</li>
<li>domain: 크롤링할 domain</li>
<li>start_urls: 가장 먼저 크롤링을 시작할 (처음에 request를 던질) url</li>
</ul>
</li>
</ul>
<h4 id="크롤링-함수-작성"><a href="#크롤링-함수-작성" class="headerlink" title="크롤링 함수 작성"></a>크롤링 함수 작성</h4><p>먼저, jupyter notebook 상에서 네이버 영화 페이지에서 현재 상영영화 링크 리스트 크롤링해본다.<br>(jupyter notebook 상에서 크롤링이 제대로 되는지 확인해보고, 파이썬 파일로 작성하기 위함)</p>
<ul>
<li>상영중인 영화 리스트 받아오기</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">url = <span class="string">"https://movie.naver.com/movie/running/current.nhn"</span></span><br><span class="line">rep = requests.get(url)</span><br><span class="line">response = TextResponse(rep.url, body=rep.text, encoding=<span class="string">"utf-8"</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">links = response.xpath(<span class="string">'//*[@id="content"]/div[1]/div[1]/div[3]/ul/li/dl/dt/a/@href'</span>)[:<span class="number">10</span>].extract()</span><br><span class="line"><span class="keyword">for</span> link <span class="keyword">in</span> links:</span><br><span class="line">    print(response.urljoin(link))    <span class="comment"># domain과 연결시켜줌</span></span><br></pre></td></tr></table></figure>
<pre><code>https://movie.naver.com/movie/bi/mi/basic.nhn?code=167105
https://movie.naver.com/movie/bi/mi/basic.nhn?code=119428
https://movie.naver.com/movie/bi/mi/basic.nhn?code=155356
https://movie.naver.com/movie/bi/mi/basic.nhn?code=168050
https://movie.naver.com/movie/bi/mi/basic.nhn?code=163533
https://movie.naver.com/movie/bi/mi/basic.nhn?code=168023
https://movie.naver.com/movie/bi/mi/basic.nhn?code=178402
https://movie.naver.com/movie/bi/mi/basic.nhn?code=164992
https://movie.naver.com/movie/bi/mi/basic.nhn?code=172040
https://movie.naver.com/movie/bi/mi/basic.nhn?code=97612
</code></pre><ul>
<li>영화의 제목과 누적 관객수 받아오기</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">url = <span class="string">"https://movie.naver.com/movie/bi/mi/basic.nhn?code=159892"</span></span><br><span class="line">rep = requests.get(url)</span><br><span class="line">response = TextResponse(rep.url, body=rep.text, encoding=<span class="string">"utf-8"</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_page_contents</span><span class="params">(self, response)</span>:</span></span><br><span class="line">    item = CrawlerItem()</span><br><span class="line">    item[<span class="string">"title"</span>] = response.xpath(<span class="string">'//*[@id="content"]/div[1]/div[2]/div[1]/h3/a[1]/text()'</span>).extract()[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        item[<span class="string">"count"</span>] = response.xpath(<span class="string">'//*[@id="content"]/div[1]/div[2]/div[1]/dl/dd[5]/div/p[2]/text()'</span>).extract()[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        item[<span class="string">"count"</span>] = <span class="string">"0명"</span></span><br><span class="line">    <span class="keyword">yield</span> item</span><br></pre></td></tr></table></figure>
<h4 id="nm-spider-py-작성"><a href="#nm-spider-py-작성" class="headerlink" title="nm_spider.py 작성"></a>nm_spider.py 작성</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#######################################################################################</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> crawler.items <span class="keyword">import</span> CrawlerItem    <span class="comment"># 위에서 작성한 items.py를 불러옴</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># start_urls -&gt; parse -&gt; parse_page_contents 순으로 호출</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NaverMovieSpider</span><span class="params">(scrapy.Spider)</span>:</span>    <span class="comment"># scrapy.Spider 클래스를 상속 받음 (크롤링에 필요한 기능이 들어가 있음)</span></span><br><span class="line">    name = <span class="string">"naver_movie"</span>   </span><br><span class="line">    allow_domain = [<span class="string">"https://movie.naver.com"</span>]</span><br><span class="line">    start_urls = [</span><br><span class="line">        <span class="string">"https://movie.naver.com/movie/running/current.nhn"</span></span><br><span class="line">    ]    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># link 리스트를 가져옴 (start url을 request로 던지고 그 response를 parse 함수가 받음)</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        links = response.xpath(<span class="string">'//*[@id="content"]/div[1]/div[1]/div[3]/ul/li/dl/dt/a/@href'</span>)[:<span class="number">10</span>].extract()</span><br><span class="line">        <span class="keyword">for</span> link <span class="keyword">in</span> links:</span><br><span class="line">            link = response.urljoin(link)</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(link, callback=self.parse_page_contents)  <span class="comment"># yield가 10개 생성됨</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 각페이지의 link로 접속하여 데이터를 가져옴</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_page_contents</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        item = CrawlerItem()    <span class="comment"># item obj.를 만들어 줌</span></span><br><span class="line">        item[<span class="string">"title"</span>] = response.xpath(<span class="string">'//*[@id="content"]/div[1]/div[2]/div[1]/h3/a[1]/text()'</span>).extract()[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            item[<span class="string">"count"</span>] = response.xpath(<span class="string">'//*[@id="content"]/div[1]/div[2]/div[1]/dl/dd[5]/div/p[2]/text()'</span>).extract()[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            item[<span class="string">"count"</span>] = <span class="string">"0명"</span></span><br><span class="line">        <span class="keyword">yield</span> item      <span class="comment"># 10개 만들어진 generator마다 한 번 실행됨</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#######################################################################################</span></span><br></pre></td></tr></table></figure>
<h4 id="3-settings-py"><a href="#3-settings-py" class="headerlink" title="(3) settings.py"></a>(3) settings.py</h4><ul>
<li>크롤링하려는 사이트의 robots.txt 정책에 따라 obey 여부를 조정</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#######################################################################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Obey robots.txt rules</span></span><br><span class="line">ROBOTSTXT_OBEY = <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#######################################################################################</span></span><br></pre></td></tr></table></figure>
<h4 id="4-spider-실행"><a href="#4-spider-실행" class="headerlink" title="(4) spider 실행"></a>(4) spider 실행</h4><ul>
<li>실행 위치: 프로젝트 디렉토리에서 실행(item.py 파일이 있는 디렉토리)</li>
<li>명령어<ul>
<li><code>$ scrapy crawl naver_movie</code></li>
<li>csv 파일로 결과 저장 옵션: <code>$ scrapy crawl naver_movie -o movie.csv</code><ul>
<li>단, 이렇게 저장하면 column 순서를 지정할 수 없음 (pipeline으로 지정할 수 있음)</li>
</ul>
</li>
</ul>
</li>
<li>비동기 thread로 처리되기 때문에 영화 데이터가 순서대로 크롤링되지 않음</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.read_csv(<span class="string">"movie.csv"</span>)</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th></th>
<th>count</th>
<th>title</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>2,833,821명</td>
<td>암수살인</td>
</tr>
<tr>
<td>1</td>
<td>15,248명</td>
<td>리즈와 파랑새</td>
</tr>
<tr>
<td>2</td>
<td>395,867명</td>
<td>곰돌이 푸 다시 만나 행복해</td>
</tr>
<tr>
<td>3</td>
<td>0명</td>
<td>다이노 어드벤처2: 육해공 공룡 대백과</td>
</tr>
<tr>
<td>4</td>
<td>153,398명</td>
<td>스타 이즈 본</td>
</tr>
<tr>
<td>5</td>
<td>18,318명</td>
<td>극장판 가면라이더 이그제이드: 트루 엔딩</td>
</tr>
<tr>
<td>6</td>
<td>193,789명</td>
<td>미쓰백</td>
</tr>
<tr>
<td>7</td>
<td>794,815명</td>
<td>그랜드 부다페스트 호텔</td>
</tr>
<tr>
<td>8</td>
<td>5,352,401명</td>
<td>안시성</td>
</tr>
<tr>
<td>9</td>
<td>3,249,358명</td>
<td>베놈</td>
</tr>
</tbody>
</table>
<h4 id="5-pipeline-py"><a href="#5-pipeline-py" class="headerlink" title="(5) pipeline.py"></a>(5) pipeline.py</h4><ul>
<li>pipeline을 사용해서 크롤링한 데이터를 column 순서를 지정해서 csv 파일로 저장할 수 있음</li>
<li>크롤러를 실행할 때 CrawlerPipeline 객체를 생성하고 아이템을 하나씩 크롤링할 때마다 process_item 함수를 실행</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#######################################################################################</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CrawlerPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.csvwriter = csv.writer(open(<span class="string">"NaverMovie.csv"</span>,<span class="string">"wt"</span>))</span><br><span class="line">        self.csvwriter.writerow([<span class="string">"title"</span>, <span class="string">"count"</span>])</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        row = []</span><br><span class="line">        row.append(item[<span class="string">"title"</span>])</span><br><span class="line">        row.append(item[<span class="string">"count"</span>])</span><br><span class="line">        self.csvwriter.writerow(row)</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line"><span class="comment">#######################################################################################</span></span><br></pre></td></tr></table></figure>
<p>settings.py 수정 (주석 해제)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#######################################################################################</span></span><br><span class="line"></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">    <span class="string">'crawler.pipelines.CrawlerPipeline'</span>:<span class="number">300</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#######################################################################################</span></span><br></pre></td></tr></table></figure>
<p>다시 scrapy 실행시 결과 파일의 column이 title, count 순서로 만들어짐</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.read_csv(<span class="string">"NaverMovie.csv"</span>)</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th></th>
<th>title</th>
<th>count</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>암수살인</td>
<td>2,833,821명</td>
</tr>
<tr>
<td>1</td>
<td>리즈와 파랑새</td>
<td>15,248명</td>
</tr>
<tr>
<td>2</td>
<td>다이노 어드벤처2: 육해공 공룡 대백과</td>
<td>0명</td>
</tr>
<tr>
<td>3</td>
<td>곰돌이 푸 다시 만나 행복해</td>
<td>395,867명</td>
</tr>
<tr>
<td>4</td>
<td>스타 이즈 본</td>
<td>153,398명</td>
</tr>
<tr>
<td>5</td>
<td>극장판 가면라이더 이그제이드: 트루 엔딩</td>
<td>18,318명</td>
</tr>
<tr>
<td>6</td>
<td>안시성</td>
<td>5,352,401명</td>
</tr>
<tr>
<td>7</td>
<td>미쓰백</td>
<td>193,789명</td>
</tr>
<tr>
<td>8</td>
<td>그랜드 부다페스트 호텔</td>
<td>794,815명</td>
</tr>
<tr>
<td>9</td>
<td>베놈</td>
<td>3,249,358명</td>
</tr>
</tbody>
</table>
<h3 id="덧"><a href="#덧" class="headerlink" title="덧"></a>덧</h3><ul>
<li>yield, callback 구조를 이해하면 그 단계를 다양하게 구성할 수 있음</li>
<li>동적페이지를 크롤링하려면 <code>__init__()</code> 함수로 driver를 만들고 driver를 사용해서 크롤링</li>
</ul>
<p><a href="https://github.com/hyeshinoh/Study_Web/blob/master/web_11_scrapy.ipynb" target="_blank" rel="noopener">jupyter notebook으로 보기</a></p>
<h4 id="참고자료"><a href="#참고자료" class="headerlink" title="참고자료"></a>참고자료</h4><ul>
<li>패스트캠퍼스, ⟪데이터사이언스스쿨 8기⟫ 수업자료</li>
</ul>

  </div>
</article>

    <div class="blog-post-comments">
        <div id="disqus_thread">
            <noscript>Please enable JavaScript to view the comments.</noscript>
        </div>
    </div>



        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/categories/Diary">Diary</a></li>
         
          <li><a href="/categories/DataScience/">Data Science</a></li>
         
          <li><a href="/categories/Life/">Life</a></li>
         
          <li><a href="/categories/">Categories</a></li>
         
          <li><a href="/search/">Search</a></li>
        
      </ul>
    </div>

    <div id="toc-footer" style="display: none">
      <ol class="toc"><li class="toc-item toc-level-4"><a class="toc-link" href="#다룰-내용"><span class="toc-number">1.</span> <span class="toc-text">다룰 내용</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-Scrapy"><span class="toc-number"></span> <span class="toc-text">1. Scrapy</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-xpath"><span class="toc-number"></span> <span class="toc-text">2. xpath</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-xpath의-기본-문법"><span class="toc-number"></span> <span class="toc-text">2.1 xpath의 기본 문법</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-네이버-실시간-검색어-크롤링"><span class="toc-number"></span> <span class="toc-text">2.2 네이버 실시간 검색어 크롤링</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-스크래피-셸-사용"><span class="toc-number">1.</span> <span class="toc-text">(1) 스크래피 셸 사용</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-jupyter-notebook-사용"><span class="toc-number">2.</span> <span class="toc-text">(2) jupyter notebook 사용</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#웹페이지에-연결"><span class="toc-number">2.1.</span> <span class="toc-text">웹페이지에 연결</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#네이버-실시간-검색어-1위-element-객체"><span class="toc-number">2.2.</span> <span class="toc-text">네이버 실시간 검색어 1위 element 객체</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#네이버-실시간-검색어-20개-element-객체"><span class="toc-number">2.3.</span> <span class="toc-text">네이버 실시간 검색어 20개 element 객체</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#객체의-text만-추출하기"><span class="toc-number">2.4.</span> <span class="toc-text">객체의 text만 추출하기</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#문자열만-추출하기"><span class="toc-number">2.5.</span> <span class="toc-text">문자열만 추출하기</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#을-이용해서-가져오기"><span class="toc-number">2.6.</span> <span class="toc-text">.을 이용해서 가져오기</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-다음-실시간-검색어-크롤링"><span class="toc-number"></span> <span class="toc-text">2.3 다음 실시간 검색어 크롤링</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#다음-실시간-검색어-리스트-출력"><span class="toc-number">0.1.</span> <span class="toc-text">다음 실시간 검색어 리스트 출력</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-gmarket-best-item-200-크롤링"><span class="toc-number"></span> <span class="toc-text">2.4 gmarket best item 200 크롤링</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#웹페이지에-연결-1"><span class="toc-number">0.1.</span> <span class="toc-text">웹페이지에 연결</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#베스트-200-아이템-제목-문자열-리스트로-가져오기"><span class="toc-number">0.2.</span> <span class="toc-text">베스트 200 아이템 제목 문자열 리스트로 가져오기</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#200개-아이템에서-li-클래스가-first인-데이터만-가져오기"><span class="toc-number">0.3.</span> <span class="toc-text">200개 아이템에서 li 클래스가 first인 데이터만 가져오기</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#200개-아이템에서-li-클래스가-first가-아닌-데이터만-가져오기"><span class="toc-number">0.4.</span> <span class="toc-text">200개 아이템에서 li 클래스가 first가 아닌 데이터만 가져오기</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Scrapy-project"><span class="toc-number"></span> <span class="toc-text">3. Scrapy project</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-scrapy-프로젝트-생성"><span class="toc-number"></span> <span class="toc-text">3.1 scrapy 프로젝트 생성</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-scrapy-프로젝트-파일-설명"><span class="toc-number"></span> <span class="toc-text">3.2 scrapy 프로젝트 파일 설명</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#project-구조"><span class="toc-number">1.</span> <span class="toc-text">project 구조</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-크롤링-코드-작성"><span class="toc-number"></span> <span class="toc-text">3.3 크롤링 코드 작성</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#※-yield"><span class="toc-number">1.</span> <span class="toc-text">※ yield</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#iterator와-generator"><span class="toc-number">1.1.</span> <span class="toc-text">iterator와 generator</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-items-py"><span class="toc-number">2.</span> <span class="toc-text">(1) items.py</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-spider-py"><span class="toc-number">3.</span> <span class="toc-text">(2) spider.py</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#크롤링-함수-작성"><span class="toc-number">4.</span> <span class="toc-text">크롤링 함수 작성</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#nm-spider-py-작성"><span class="toc-number">5.</span> <span class="toc-text">nm_spider.py 작성</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-settings-py"><span class="toc-number">6.</span> <span class="toc-text">(3) settings.py</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-spider-실행"><span class="toc-number">7.</span> <span class="toc-text">(4) spider 실행</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-pipeline-py"><span class="toc-number">8.</span> <span class="toc-text">(5) pipeline.py</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#덧"><span class="toc-number"></span> <span class="toc-text">덧</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#참고자료"><span class="toc-number">1.</span> <span class="toc-text">참고자료</span></a></li></ol>
    </div>

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" href="http://www.facebook.com/sharer.php?u=https://hyeshinoh.github.io/2018/10/15/web_12_scrapy/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://twitter.com/share?url=https://hyeshinoh.github.io/2018/10/15/web_12_scrapy/&text=Web crawling - Scrapy"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.linkedin.com/shareArticle?url=https://hyeshinoh.github.io/2018/10/15/web_12_scrapy/&title=Web crawling - Scrapy"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=https://hyeshinoh.github.io/2018/10/15/web_12_scrapy/&is_video=false&description=Web crawling - Scrapy"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Web crawling - Scrapy&body=Check out this article: https://hyeshinoh.github.io/2018/10/15/web_12_scrapy/"><i class="fas fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://getpocket.com/save?url=https://hyeshinoh.github.io/2018/10/15/web_12_scrapy/&title=Web crawling - Scrapy"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://reddit.com/submit?url=https://hyeshinoh.github.io/2018/10/15/web_12_scrapy/&title=Web crawling - Scrapy"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.stumbleupon.com/submit?url=https://hyeshinoh.github.io/2018/10/15/web_12_scrapy/&title=Web crawling - Scrapy"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://digg.com/submit?url=https://hyeshinoh.github.io/2018/10/15/web_12_scrapy/&title=Web crawling - Scrapy"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.tumblr.com/share/link?url=https://hyeshinoh.github.io/2018/10/15/web_12_scrapy/&name=Web crawling - Scrapy&description=&lt;p&gt;&lt;a href=&#34;https://github.com/hyeshinoh/Study_Web/blob/master/web_11_scrapy.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;jupyter notebook으로 보기&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;다룰-내용&#34;&gt;&lt;a href=&#34;#다룰-내용&#34; class=&#34;headerlink&#34; title=&#34;다룰 내용&#34;&gt;&lt;/a&gt;다룰 내용&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;Scrapy 개요&lt;/li&gt;
&lt;li&gt;xpath&lt;ul&gt;
&lt;li&gt;xpath의 기본 문법&lt;/li&gt;
&lt;li&gt;scrapy shell 환경에서 xpath&lt;/li&gt;
&lt;li&gt;scrapy jupyter notebook xpath&lt;/li&gt;
&lt;li&gt;네이버 실시간 검색어, 다음실시간 검색어, 지마켓 베스트 200&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;scrapy 프로젝트를 만들어서 크롤링&lt;ul&gt;
&lt;li&gt;네이버 영화 사이트에서 현재 상영영화 링크를 크롤링&lt;/li&gt;
&lt;li&gt;크롤링한 링크에서 영화 제목과 누적관객수 데이터를 크롤링&lt;/li&gt;
&lt;li&gt;csv 파일로 저장&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;"><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fas fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fas fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> Share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy; 2019 우와팬더
  </div>
  <div class="footer-right">
    <nav>
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/categories/Diary">Diary</a></li>
         
          <li><a href="/categories/DataScience/">Data Science</a></li>
         
          <li><a href="/categories/Life/">Life</a></li>
         
          <li><a href="/categories/">Categories</a></li>
         
          <li><a href="/search/">Search</a></li>
        
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
<link rel="stylesheet" href="/lib/justified-gallery/css/justifiedGallery.min.css">

    <!-- jquery -->
<script src="/lib/jquery/jquery.min.js"></script>
<script src="/lib/justified-gallery/js/jquery.justifiedGallery.min.js"></script>
<!-- clipboard -->

  <script src="/lib/clipboard/clipboard.min.js"></script>
  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"Copy to clipboard!\">";
    btn += '<i class="far fa-clone"></i>';
    btn += '</span>'; 
    // mount it!
    $(".highlight .code pre").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      target: function(trigger) {
        return trigger.nextElementSibling;
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "Copied!");
      e.clearSelection();
    })
  })
  </script>

<script src="/js/main.js"></script>
<!-- search -->

<!-- Google Analytics -->

    <script type="text/javascript">
        (function(i,s,o,g,r,a,m) {i['GoogleAnalyticsObject']=r;i[r]=i[r]||function() {
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
        ga('create', 'UA-126954393-1', 'auto');
        ga('send', 'pageview');
    </script>

<!-- Baidu Analytics -->

<!-- Disqus Comments -->

    <script type="text/javascript">
        var disqus_shortname = 'hyeshinoh';

        (function(){
            var dsq = document.createElement('script');
            dsq.type = 'text/javascript';
            dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        }());
    </script>


<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<!-- <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML'></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->

</body>
</html>
